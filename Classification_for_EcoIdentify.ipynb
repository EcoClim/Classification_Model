{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EcoClim/Classification_Model/blob/main/Classification_for_EcoIdentify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fitted-rebate",
      "metadata": {
        "id": "fitted-rebate"
      },
      "source": [
        "#**EcoIdentify**\n",
        "## **Classifying Recycling Material**\n",
        "###Built by EcoClim Solutions\n",
        "\n",
        "---\n",
        "Garbage classification involves separating wastes according to how it's handled or processed. It's important for recycling as some materials are recyclable and others are not.\n",
        "\n",
        "\n",
        "![AI Logo](https://ecoclimsolutions.files.wordpress.com/2023/12/rmcai.png?resize=219%2C219)\n",
        "---\n",
        "\n",
        "The objective of the notebook is to build a model that helps to classify recycling material, known as EcoIdentify\n",
        "\n",
        "---\n",
        "All code is licensed under MIT License. To view terms and conditions visit this [information page](https://mit-license.org/)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PvCG8Zm_--Fo",
      "metadata": {
        "id": "PvCG8Zm_--Fo"
      },
      "source": [
        "#**1. Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "olive-bumper",
      "metadata": {
        "id": "olive-bumper"
      },
      "source": [
        "### **About The Data And Datasets:**\n",
        "* The [Dataset](https://drive.google.com/file/d/1brl6_ul9a0ILv0bylr_7ggrIQIhEBAx6/view?usp=drive_link) used is an altered version of a [Dataset](https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification) found in Kaggle\n",
        "* The total number of images in the dataset is 2527.\n",
        "* The dataset has 6 different classes.\n",
        "* **The number of images in each class varies**.\n",
        "  * The **_Paper_** class has 594 images\n",
        "  * The  **_Cardboard_** class has 403 images\n",
        "  * The  **_Plastic_** class has 482 images\n",
        "  * The  **_Glass_** class has 501 images\n",
        "  * The  **_Metal_** class has 410 images\n",
        "  * The  **_Trash_** class has 137 images"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vmCVJP246Qy0",
      "metadata": {
        "id": "vmCVJP246Qy0"
      },
      "source": [
        "##**1.1 Importing Dependencies And Mounting Drive**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aquatic-belize",
      "metadata": {
        "id": "aquatic-belize"
      },
      "outputs": [],
      "source": [
        "#Importing Dependencies\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jzFMOA-qZUkB",
      "metadata": {
        "id": "jzFMOA-qZUkB"
      },
      "outputs": [],
      "source": [
        "#Mounting Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fancy-knight",
      "metadata": {
        "id": "fancy-knight"
      },
      "source": [
        "## **1.2 Downloading and Storing the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kVYwH7Ub70Yi",
      "metadata": {
        "id": "kVYwH7Ub70Yi"
      },
      "outputs": [],
      "source": [
        "#Downloading Dataset\n",
        "!gdown 1brl6_ul9a0ILv0bylr_7ggrIQIhEBAx6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wi_Tnwz-9WQh",
      "metadata": {
        "id": "Wi_Tnwz-9WQh"
      },
      "outputs": [],
      "source": [
        "#Changing location of Dataset\n",
        "!mv /content/Dataset.zip /content/drive/MyDrive/Dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdd4fwpWZRzw",
      "metadata": {
        "id": "bdd4fwpWZRzw"
      },
      "outputs": [],
      "source": [
        "#Unizipping the Datset\n",
        "!unzip '/content/drive/MyDrive/Dataset.zip' -d my_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "flexible-treasury",
      "metadata": {
        "id": "flexible-treasury"
      },
      "outputs": [],
      "source": [
        "#Declaring the Dataset's path as a variable\n",
        "data_dir = 'my_data/Dataset/'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F0qeYEmt-M0k",
      "metadata": {
        "id": "F0qeYEmt-M0k"
      },
      "source": [
        "##**1.3 Reviewing the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "moving-kitchen",
      "metadata": {
        "id": "moving-kitchen"
      },
      "outputs": [],
      "source": [
        "#Reviewing number of files and directories in the Dataset\n",
        "total_dir = len(os.listdir(data_dir))\n",
        "total_files = 0\n",
        "\n",
        "for dirname, _, filenames in os.walk(data_dir):\n",
        "    print('counting:', dirname)\n",
        "    files_counter = 0\n",
        "    for file in filenames:\n",
        "        files_counter += 1\n",
        "    total_files += files_counter\n",
        "    print('total files in dir:', files_counter)\n",
        "\n",
        "print('--------')\n",
        "print('total number of files',total_files)\n",
        "print('total number of directories',total_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BE-CX1tk-Wi6",
      "metadata": {
        "id": "BE-CX1tk-Wi6"
      },
      "source": [
        "##**1.4 Adjusting The Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "informative-diving",
      "metadata": {
        "id": "informative-diving"
      },
      "outputs": [],
      "source": [
        "#Creating the Training and Validation Datasets\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=100\n",
        ")\n",
        "\n",
        "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=100\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeX7wJMT-g9q",
      "metadata": {
        "id": "aeX7wJMT-g9q"
      },
      "source": [
        "##**1.5 Validating The Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "prerequisite-washer",
      "metadata": {
        "id": "prerequisite-washer"
      },
      "outputs": [],
      "source": [
        "#Geting class names\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hf58V2aJ-qNz",
      "metadata": {
        "id": "Hf58V2aJ-qNz"
      },
      "source": [
        "##**1.6 Viewing And Inspecting The Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "thrown-garden",
      "metadata": {
        "id": "thrown-garden"
      },
      "outputs": [],
      "source": [
        "#Viewing some images from the Training Dataset\n",
        "plt.figure(figsize=(16, 16))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(12):\n",
        "        ax = plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vocal-reputation",
      "metadata": {
        "id": "vocal-reputation"
      },
      "outputs": [],
      "source": [
        "#Viewing some images from the Validation Dataset\n",
        "plt.figure(figsize=(16, 16))\n",
        "for images, labels in validation_ds.take(1):\n",
        "    for i in range(12):\n",
        "        ax = plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "separated-flour",
      "metadata": {
        "id": "separated-flour"
      },
      "outputs": [],
      "source": [
        "#Inspect the Training Dataset\n",
        "train_batch = train_ds.as_numpy_iterator().next()\n",
        "\n",
        "print('total of batches:',len(train_ds))\n",
        "print('images batch shape:',train_batch[0].shape)\n",
        "print('labels batch shape:',train_batch[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adjacent-drinking",
      "metadata": {
        "id": "adjacent-drinking"
      },
      "outputs": [],
      "source": [
        "#Inspect the Validation Dataset\n",
        "validation_batch = validation_ds.as_numpy_iterator().next()\n",
        "\n",
        "print('total of batches:',len(validation_ds))\n",
        "print('images batch shape:',validation_batch[0].shape)\n",
        "print('labels batch shape:',validation_batch[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "banned-toilet",
      "metadata": {
        "id": "banned-toilet"
      },
      "source": [
        "# **2. Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aZpBMInDDNGt",
      "metadata": {
        "id": "aZpBMInDDNGt"
      },
      "source": [
        "##**2.1 Instantiating ResNet50V2 for fine-tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "prospective-indianapolis",
      "metadata": {
        "id": "prospective-indianapolis"
      },
      "outputs": [],
      "source": [
        "#Instantiating the base model\n",
        "input_shape = (256,256,3)\n",
        "base_model = tf.keras.applications.ResNet50V2(include_top=False, input_shape=input_shape)\n",
        "\n",
        "#Making the layers of the model trainable\n",
        "base_model.trainable = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7amLvSclFFEO",
      "metadata": {
        "id": "7amLvSclFFEO"
      },
      "source": [
        "##**2.2 Reviewing the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "directed-lloyd",
      "metadata": {
        "id": "directed-lloyd"
      },
      "outputs": [],
      "source": [
        "#Reviewing the base model architecture\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "organizational-frame",
      "metadata": {
        "id": "organizational-frame"
      },
      "outputs": [],
      "source": [
        "#Finding the tunning layer and its index\n",
        "tuning_layer_name = 'conv5_block1_preact_bn'\n",
        "tuning_layer = base_model.get_layer(tuning_layer_name)\n",
        "tuning_index = base_model.layers.index(tuning_layer)\n",
        "\n",
        "#Freezing all the layers before the tuning layer\n",
        "for layer in base_model.layers[:tuning_index]:\n",
        "    layer.trainable =  False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J6083NFwFPio",
      "metadata": {
        "id": "J6083NFwFPio"
      },
      "source": [
        "##**2.3 Changing Orientation of Images for Better Precision**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cosmetic-reputation",
      "metadata": {
        "id": "cosmetic-reputation"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(1./127.5, offset=-1),\n",
        "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oI23JGDUFqns",
      "metadata": {
        "id": "oI23JGDUFqns"
      },
      "source": [
        "##**2.4 Creating the architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "controlled-netscape",
      "metadata": {
        "id": "controlled-netscape"
      },
      "outputs": [],
      "source": [
        "#Creating the neural network architecture\n",
        "import tensorflow as tf\n",
        "model = tf.keras.Sequential([\n",
        "    data_augmentation,\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "learning_rate = 0.00001\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YBvu5PRgFywc",
      "metadata": {
        "id": "YBvu5PRgFywc"
      },
      "source": [
        "##**2.5 Training the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "posted-latitude",
      "metadata": {
        "id": "posted-latitude"
      },
      "outputs": [],
      "source": [
        "#Training the model\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=validation_ds,\n",
        "    epochs=100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "textile-nepal",
      "metadata": {
        "id": "textile-nepal"
      },
      "outputs": [],
      "source": [
        "#Visualizing the training history\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "#Plotting accuracy\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "#Plotting loss\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "quantitative-shape",
      "metadata": {
        "id": "quantitative-shape"
      },
      "source": [
        "# **3. Model Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7nKYGe67GJr4",
      "metadata": {
        "id": "7nKYGe67GJr4"
      },
      "source": [
        "##**3.1 Evaluating the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "incomplete-improvement",
      "metadata": {
        "id": "incomplete-improvement"
      },
      "outputs": [],
      "source": [
        "#Verifying the performance of the model\n",
        "loss, accuracy = model.evaluate(validation_ds)\n",
        "print('Test accuracy :', accuracy)\n",
        "print('Test loss:', loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mZkz0Yh9GUTS",
      "metadata": {
        "id": "mZkz0Yh9GUTS"
      },
      "source": [
        "##**3.2 Saving the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tewzIN8GAT_z",
      "metadata": {
        "id": "tewzIN8GAT_z"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/EcoIdentify_classification_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As of **December 23, 2025**, a newer version of Tensorflow has been released, which creates version mismatch and produces an error on deployment. To overcome this issue, run the following code and convert the model."
      ],
      "metadata": {
        "id": "k4FUJO_c2tTK"
      },
      "id": "k4FUJO_c2tTK"
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/EcoIdentify_classification_model.h5\")\n",
        "model.export(\"/content/drive/MyDrive/EcoIdentify_savedmodel\")"
      ],
      "metadata": {
        "id": "XtglTwgx3BGq"
      },
      "id": "XtglTwgx3BGq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "saved-possible",
      "metadata": {
        "id": "saved-possible"
      },
      "source": [
        "# **4. Inferencing**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "coordinate-shower",
      "metadata": {
        "id": "coordinate-shower"
      },
      "source": [
        "## **4.1. Inference Using Known Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "legislative-possession",
      "metadata": {
        "id": "legislative-possession",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#Get a batch from Validation Dataset to do some inferencing\n",
        "image_batch, label_batch = validation_ds.as_numpy_iterator().next()\n",
        "\n",
        "#Inference\n",
        "inference = model.predict_on_batch(image_batch)\n",
        "\n",
        "#Viewing images and labels\n",
        "plt.figure(figsize=(18, 18))\n",
        "for i in range(12):\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(image_batch[i].astype(\"uint8\"))\n",
        "    plt.title('Inference:{}, {:.2f}% Confidence\\nReal Label:{}'\n",
        "              .format(class_names[np.argmax(inference[i])], 100 * np.max(inference[i]), class_names[label_batch[i]]))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GkK16C5adtdy",
      "metadata": {
        "id": "GkK16C5adtdy"
      },
      "source": [
        "#Ending Notes\n",
        "\n",
        "The model should've saved a file named *EcoIdentify_savedmodel* in my drive. Refer to [deployment](https://huggingface.co/spaces/EcoClim-Solution/EcoIdentify) to learn how to use this file.\n",
        "\n",
        "Similar model was also created using Roboflow. To view this, visit our Roboflow deployment at [Streamlit](https://ecoidentifyv3.streamlit.app/)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PvCG8Zm_--Fo",
        "vmCVJP246Qy0",
        "fancy-knight",
        "F0qeYEmt-M0k",
        "BE-CX1tk-Wi6",
        "aeX7wJMT-g9q",
        "Hf58V2aJ-qNz",
        "banned-toilet",
        "aZpBMInDDNGt",
        "7amLvSclFFEO",
        "J6083NFwFPio",
        "oI23JGDUFqns",
        "YBvu5PRgFywc",
        "quantitative-shape",
        "7nKYGe67GJr4",
        "mZkz0Yh9GUTS",
        "saved-possible"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 255.910772,
      "end_time": "2021-05-06T21:58:34.144470",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-05-06T21:54:18.233698",
      "version": "2.3.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}